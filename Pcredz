#!/usr/bin/env python3
# PCredz 2.1.0
# https://github.com/lgandx/PCredz
#
# Created by Laurent Gaffie
# Contact: lgaffie@secorizon.com
# X: @secorizon
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.

import sys
import os

# ANSI color codes for terminal output (defined early for use in error messages)
class Colors:
    """ANSI color codes - simplified color scheme"""
    RESET = '\033[0m'
    CYAN = '\033[96m'    
    GREEN = '\033[1;92m'  # For labels (Host:, Request:, etc.)
    RED = '\033[91m'     # For sensitive data (passwords, tokens)
    YELLOW_BOLD = '\033[1;33m'  # For packet header (IP addresses and ports)

def supports_color():
    """Check if terminal supports color output"""
    # Check if output is redirected
    if not sys.stdout.isatty():
        return False
    # Check platform
    if sys.platform == 'win32':
        # Windows 10+ supports ANSI colors
        return True
    # Unix-like systems typically support colors
    return 'TERM' in os.environ and os.environ['TERM'] != 'dumb'

# Enable/disable colors based on terminal support
USE_COLORS = supports_color()

def colorize(text, color):
    """Apply color to text if colors are enabled"""
    if USE_COLORS:
        return f'{color}{text}{Colors.RESET}'
    return text

# Now import other modules
try:
    import pcapy
except ImportError:
    print("pcapy-ng is not installed.")
    print("Install: pip3 install pcapy-ng")
    exit(1)

import datetime
import argparse
import re
import time
import logging
import base64
import struct
import binascii
import signal

VERSION = 'PCredz 2.1.0'

# Global state
ntlm_challenge = {}
ftp_users = {}
seen_credentials = set()
logged_messages = set()
detected_offset = None
disabled_protocols = set()  # Protocols to skip
excluded_hosts = set()  # IPs to exclude from capture
http_flows = {}  # Store HTTP requests/responses for pairing: {(src, sport, dst, dport): {'request': payload, 'response': payload}}

# Pre-compiled regex patterns
REGEX_HTTP_BASIC = re.compile(rb'Authorization: Basic ([A-Za-z0-9+/=]+)', re.IGNORECASE)
REGEX_NTLM_CHALLENGE = re.compile(rb'(?:WWW|Proxy)-Authenticate: NTLM ([A-Za-z0-9+/=]+)', re.IGNORECASE)
REGEX_NTLM_AUTH = re.compile(rb'(?:Authorization|Proxy-Authorization): NTLM ([A-Za-z0-9+/=]+)', re.IGNORECASE)
REGEX_PASSWORD_FIELDS = re.compile(
    r'(?:^|&)([^&=]*?(?:password|pass|_password|passwd|session_password|sessionpassword|'
    r'login_password|loginpassword|form_pw|pw|userpassword|pwd|upassword|'
    r'passwort|passwrd|wppassword|j_password|admin_password|admin_pass|'
    r'secret|api_key|token|key|auth)[^&=]*?)\s*=\s*([^&"\s]+)',
    re.IGNORECASE | re.MULTILINE
)

# Additional regex patterns for enhanced credential detection
# Access key patterns (access_key_id, access-key-secret, LTAI*)
REGEX_ACCESS_KEY = re.compile(
    r'((?:access)[\-_]?(?:key)[\-_]?(?:id|secret)|LTAI[a-z0-9]{12,20})',
    re.IGNORECASE
)

# JavaScript password patterns
REGEX_JS_PASSWORD = re.compile(
    r'(?:[\'"])(?:[\.\w]{0,32})?[p](?:ass|wd|asswd|assword)(?:[\.\w]{0,32})?(?:[\'"])\s*(?:[:=]{1,3}|![=]{1,2}|\)?\.val\()\s*(?:[\'"])([^\'"]+?)(?:[\'"])(?:[,\)])?|'
    r'(?:[\'"])([^\'"]+?)(?:[\'"])\s*(?:[:=]{1,3}|![=]{1,2})\s*(?:[\.\w]{0,32})?[p](?:ass|wd|asswd|assword)(?:[\.\w]{0,32})?(?:[\'"])',
    re.IGNORECASE | re.MULTILINE
)

# Corp ID/Secret patterns
REGEX_CORP_CRED = re.compile(
    r'corp(?:id|secret)\s*[:=]\s*([^\s&"\'<>]+)',
    re.IGNORECASE
)

# JDBC connection strings
REGEX_JDBC = re.compile(
    r'jdbc:[a-z:]+://[a-z0-9\.\-_:;=/@?,&]+',
    re.IGNORECASE
)

# Basic/Bearer token patterns
REGEX_AUTH_TOKEN = re.compile(
    r'(?:basic|bearer)\s+([a-z0-9=:_\+\-\./]{5,100})',
    re.IGNORECASE
)

# JavaScript key/secret/token patterns
REGEX_JS_KEY_SECRET = re.compile(
    r'(?:[\'"])(?:[\.\w]{0,32})?(?:key|secret|token|config|auth|access|admin|ticket)(?:[\.\w]{0,32})?(?:[\'"])\s*(?:[:=]{1,3}|![=]{1,2}|\)?\.val\()\s*(?:[\'"])([^\'"]+?)(?:[\'"])(?:[,\)])?|'
    r'(?:[\'"])([^\'"]+?)(?:[\'"])\s*(?:[:=]{1,3}|![=]{1,2})\s*(?:[\.\w]{0,32})?(?:key|secret|token|config|auth|access|admin|ticket)(?:[\.\w]{0,32})?(?:[\'"])',
    re.IGNORECASE | re.MULTILINE
)

# XML Key tags
REGEX_XML_KEY = re.compile(
    r'<Key>(.*?)</Key>',
    re.IGNORECASE | re.DOTALL
)

# Cookie patterns (for Cookie and Set-Cookie headers)
REGEX_COOKIE = re.compile(
    r'(?:Cookie|Set-Cookie):\s*([^=]+(?:password|pass|_password|passwd|session_password|sessionpassword|'
    r'login_password|loginpassword|form_pw|pw|userpassword|pwd|upassword|'
    r'passwort|passwrd|wppassword|j_password|admin_password|admin_pass|'
    r'secret|api_key|token|key|auth|session|sessionid|sid|jsessionid|'
    r'csrf|xsrf|authenticity_token|access_token|refresh_token)[^=]*?)\s*=\s*([^;,\s]+)',
    re.IGNORECASE | re.MULTILINE
)

def write_data(outfile, data, key):
    """Write credentials to file with deduplication"""
    outfile_path = os.path.join(output_path, "logs", outfile)
    os.makedirs(os.path.dirname(outfile_path), exist_ok=True)
    
    cache_key = (outfile, key)
    if cache_key in seen_credentials:
        return
    
    seen_credentials.add(cache_key)
    with open(outfile_path, 'a', encoding='utf-8') as f:
        f.write(data + '\n')

def write_http_raw_with_pair(outfile, current_payload, key, flow_key, is_http_response):
    """Write HTTP packet to file with paired request/response"""
    outfile_path = os.path.join(output_path, "logs", outfile)
    os.makedirs(os.path.dirname(outfile_path), exist_ok=True)
    
    cache_key = (outfile, key)
    if cache_key in seen_credentials:
        return
    
    seen_credentials.add(cache_key)
    
    # Get paired request/response
    # When writing a response, include the paired request if available
    # When writing a request, include the paired response if available
    paired_data = ""
    if flow_key in http_flows:
        flow_data = http_flows[flow_key]
        if is_http_response and 'request' in flow_data:
            # Writing response, include request
            paired_data = "=== REQUEST ===\n" + flow_data['request'] + "\n\n"
        elif not is_http_response and 'response' in flow_data:
            # Writing request, include response
            paired_data = "=== RESPONSE ===\n" + flow_data['response'] + "\n\n"
    
    # Write current packet with paired data
    current_type = 'RESPONSE' if is_http_response else 'REQUEST'
    full_data = paired_data + f"=== {current_type} ===\n" + current_payload
    
    with open(outfile_path, 'a', encoding='utf-8') as f:
        f.write(full_data + '\n\n')

def get_packet_info(src, sport, dst, dport):
    """Generate packet info string with optional timestamp and colors"""
    ts = f'[{datetime.datetime.fromtimestamp(time.time())}] ' if args.timestamp else ''
    # Colorize IP addresses and ports with yellow bold
    header = f'{src}:{sport} > {dst}:{dport}'
    return f'{ts}{colorize(header, Colors.YELLOW_BOLD)}'

def colorize_message(message):
    """Add colors to message - labels in green, matched patterns from regex rules in red"""
    lines = message.split('\n')
    colored_lines = []
    
    # List of all regex patterns to use for highlighting
    regex_patterns = [
        REGEX_PASSWORD_FIELDS,
        REGEX_ACCESS_KEY,
        REGEX_CORP_CRED,
        REGEX_JDBC,
        REGEX_AUTH_TOKEN,
        REGEX_JS_PASSWORD,
        REGEX_JS_KEY_SECRET,
        REGEX_XML_KEY
    ]
    
    for line in lines:
        if not line.strip():
            colored_lines.append(line)
            continue
        
        # Colorize labels
        if line.startswith('Host:'):
            parts = line.split(':', 1)
            if len(parts) == 2:
                label = colorize('Host:', Colors.GREEN)
                content = parts[1].strip()
                # Highlight matched patterns in content using existing regex rules
                colored_content = highlight_matches(content, regex_patterns)
                colored_lines.append(f'{label} {colored_content}')
            else:
                colored_lines.append(line)
        
        elif 'Potential password submission:' in line:
            label = colorize('Potential password submission:', Colors.GREEN)
            colored_lines.append(label)
        
        elif line.startswith('Request:') or line.startswith('Response:'):
            parts = line.split(':', 1)
            if len(parts) == 2:
                label = colorize(parts[0] + ':', Colors.GREEN)
                content = parts[1].strip()
                # Highlight matched patterns in content using existing regex rules
                colored_content = highlight_matches(content, regex_patterns)
                colored_lines.append(f'{label} {colored_content}')
            else:
                colored_lines.append(line)
        
        else:
            # Highlight matched patterns in other lines
            colored_line = highlight_matches(line, regex_patterns)
            colored_lines.append(colored_line)
    
    return '\n'.join(colored_lines)

def highlight_matches(text, patterns):
    """Highlight all matches from regex patterns in text with red color"""
    if not text:
        return text
    
    # Collect all matches with their positions
    matches = []
    for pattern in patterns:
        for match in pattern.finditer(text):
            matches.append((match.start(), match.end(), match.group(0)))
    
    # Sort by position (reverse order for easier replacement)
    matches.sort(key=lambda x: x[0], reverse=True)
    
    # Apply colorization from end to start to preserve positions
    colored_text = text
    for start, end, matched_text in matches:
        if start < len(colored_text) and end <= len(colored_text):
            # Check if this part hasn't been colored yet
            if matched_text in colored_text[start:end]:
                colored_text = colored_text[:start] + colorize(matched_text, Colors.RED) + colored_text[end:]
    
    return colored_text

def print_and_log(src, sport, dst, dport, message, credential_key=None):
    """Print and log message with deduplication (unless verbose)
    
    Args:
        credential_key: Unique identifier for this credential (for deduplication)
                       If None, always prints
    """
    head = get_packet_info(src, sport, dst, dport)
    # Colorize message for console output
    colored_message = colorize_message(message)
    full_msg = f'{head}\n{colored_message}\n'
    
    # Always log to file (without colors)
    plain_msg = f'{head}\n{message}\n'
    logger.warning(plain_msg.rstrip('\n'))
    
    # Print to console: always if verbose, once per credential if not verbose
    if args.verbose:
        print(full_msg)
    elif credential_key is None:
        print(full_msg)
    elif credential_key not in logged_messages:
        print(full_msg)
        logged_messages.add(credential_key)

def get_flow_key(src, sport, dst, dport):
    """Generate consistent flow identifier"""
    return (src, sport, dst, dport) if sport > dport else (dst, dport, src, sport)

def is_protocol_disabled(protocol):
    """Check if a protocol is disabled"""
    return protocol.upper() in disabled_protocols

def extract_ntlm(payload, src, sport, dst, dport):
    """Extract NTLM authentication (Type 2 Challenge, Type 3 Response)"""
    if is_protocol_disabled('NTLM'):
        return
        
    flow = get_flow_key(src, sport, dst, dport)
    reverse_flow = get_flow_key(dst, dport, src, sport)
    pos = 0
    
    while pos < len(payload):
        idx = payload.find(b'NTLMSSP\x00', pos)
        if idx == -1:
            break
            
        blob = payload[idx:]
        if len(blob) < 20:
            break
            
        try:
            msg_type = struct.unpack('<I', blob[8:12])[0]
            
            if msg_type == 2 and len(blob) >= 32:
                # NTLM Type 2 (Challenge)
                challenge = binascii.hexlify(blob[24:32]).upper().decode()
                ntlm_challenge[flow] = challenge
                ntlm_challenge[reverse_flow] = challenge
                
            elif msg_type == 3 and len(blob) >= 64:
                # NTLM Type 3 (Response)
                lm_len = struct.unpack('<H', blob[12:14])[0]
                lm_off = struct.unpack('<H', blob[16:18])[0]
                nt_len = struct.unpack('<H', blob[20:22])[0]
                nt_off = struct.unpack('<H', blob[24:26])[0]
                dom_len = struct.unpack('<H', blob[28:30])[0]
                dom_off = struct.unpack('<H', blob[32:34])[0]
                user_len = struct.unpack('<H', blob[36:38])[0]
                user_off = struct.unpack('<H', blob[40:42])[0]
                
                domain = blob[dom_off:dom_off + dom_len].decode('utf-16le', errors='ignore').strip('\x00')
                user = blob[user_off:user_off + user_len].decode('utf-16le', errors='ignore').strip('\x00')
                lm_resp = binascii.hexlify(blob[lm_off:lm_off + lm_len]).upper().decode()
                nt_resp = binascii.hexlify(blob[nt_off:nt_off + nt_len]).upper().decode()
                
                challenge = ntlm_challenge.get(flow) or ntlm_challenge.get(reverse_flow) or '0000000000000000'
                
                if nt_len > 24:
                    # NTLMv2
                    hash_line = f'{user}::{domain}:{challenge}:{nt_resp[:32]}:{nt_resp[32:]}'
                    msg = f'NTLMv2 complete hash is: {hash_line}'
                    write_data('NTLMv2.txt', hash_line, user)
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'NTLMv2:{user}@{domain}')
                elif nt_len == 24:
                    # NTLMv1
                    hash_line = f'{user}::{domain}:{lm_resp}:{nt_resp}:{challenge}'
                    msg = f'NTLMv1 complete hash is: {hash_line}'
                    write_data('NTLMv1.txt', hash_line, user)
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'NTLMv1:{user}@{domain}')
                    
        except (struct.error, UnicodeDecodeError, IndexError):
            pass
            
        pos = idx + 8

def extract_ntlm_from_http(payload, src, sport, dst, dport):
    """Extract NTLM from HTTP headers"""
    if is_protocol_disabled('NTLM'):
        return
        
    # Challenge
    challenge_match = REGEX_NTLM_CHALLENGE.search(payload)
    if challenge_match:
        try:
            blob = base64.b64decode(challenge_match.group(1))
            if len(blob) >= 32 and blob[:8] == b'NTLMSSP\x00' and struct.unpack('<I', blob[8:12])[0] == 2:
                flow = get_flow_key(src, sport, dst, dport)
                reverse_flow = get_flow_key(dst, dport, src, sport)
                challenge = binascii.hexlify(blob[24:32]).upper().decode()
                ntlm_challenge[flow] = challenge
                ntlm_challenge[reverse_flow] = challenge
        except (base64.binascii.Error, struct.error, IndexError):
            pass
    
    # Response
    auth_match = REGEX_NTLM_AUTH.search(payload)
    if auth_match:
        try:
            blob = base64.b64decode(auth_match.group(1))
            if b'NTLMSSP\x00' in blob:
                extract_ntlm(blob, src, sport, dst, dport)
        except (base64.binascii.Error, ValueError):
            pass

def extract_http_basic(payload, src, sport, dst, dport):
    """Extract HTTP Basic authentication"""
    if is_protocol_disabled('HTTP'):
        return
        
    basic_match = REGEX_HTTP_BASIC.search(payload)
    if basic_match:
        try:
            creds_bytes = base64.b64decode(basic_match.group(1))
            creds = creds_bytes.decode('utf-8', errors='ignore')
            if ':' in creds:
                user, pwd = creds.split(':', 1)
                if user and pwd:
                    msg = f'Found HTTP Basic authentication: {creds}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'HTTP-Basic:{creds}')
                    write_data('HTTP-Basic.txt', creds, creds)
        except (base64.binascii.Error, UnicodeDecodeError):
            pass

def extract_http_password_fields(payload, src, sport, dst, dport, enable_https, enable_http_response=False, enable_cookie=False):
    """Extract password-like fields from HTTP requests and optionally responses"""
    if is_protocol_disabled('HTTP'):
        return
        
    if not enable_https and (dport in {443, 8443} or sport in {443, 8443}):
        return
        
    try:
        payload_str = payload.decode('utf-8', errors='ignore')
    except (UnicodeDecodeError, AttributeError):
        return
    
    # Extract Host from HTTP request header
    # Normalize line endings: replace \r\n with \n, then split
    payload_normalized = payload_str.replace('\r\n', '\n').replace('\r', '\n')
    lines = payload_normalized.split('\n')
    
    # Check if this is an HTTP request or response
    # HTTP requests start with methods like GET, POST, PUT, etc.
    # HTTP responses start with "HTTP/"
    if not lines or not lines[0]:
        return
    first_line = lines[0].strip()
    first_line_upper = first_line.upper()
    http_methods = ['GET', 'POST', 'PUT', 'DELETE', 'HEAD', 'OPTIONS', 'PATCH', 'TRACE', 'CONNECT']
    is_http_request = any(first_line_upper.startswith(method + ' ') for method in http_methods)
    is_http_response = first_line_upper.startswith('HTTP/')
    
    # Skip if not HTTP request/response, or skip response if not enabled
    if not is_http_request and not is_http_response:
        return
    if is_http_response and not enable_http_response:
        return
    
    # Get flow key for request/response pairing
    flow_key = get_flow_key(src, sport, dst, dport)
    
    # Store request/response for pairing
    if flow_key not in http_flows:
        http_flows[flow_key] = {}
    if is_http_request:
        http_flows[flow_key]['request'] = payload_normalized
    else:
        http_flows[flow_key]['response'] = payload_normalized
    
    # Extract HTTP method and path from request line
    http_method = None
    http_path = None
    if is_http_request:
        # Parse request line: "METHOD /path HTTP/1.1"
        parts = first_line.split(' ', 2)
        if len(parts) >= 2:
            http_method = parts[0]
            http_path = parts[1]
    
    host = None
    # Search for Host header in all lines (usually in the second line, but can be anywhere)
    # Note: HTTP responses typically don't have Host header, so host will be None for responses
    for line in lines:
        line_stripped = line.strip()
        # Match "Host:" at the start of the line (case-insensitive)
        if line_stripped.lower().startswith('host:'):
            # Extract host value, handling formats like "Host: example.com" or "Host: example.com:8080"
            # Keep the full host value including port if present
            # Split on "Host:" (case-insensitive) to get the value part
            parts = line_stripped.split(':', 1)
            if len(parts) == 2:
                host = parts[1].strip()
                break
    
    # For HTTP responses without Host header, we could use IP:port as fallback
    # But for now, we'll leave it as None to distinguish from requests
    
    def should_hide_method_path(matched_line, http_method, http_path):
        """Check if matched_line already contains the HTTP method and path, so we can hide method_path_info"""
        if not http_method or not http_path or not matched_line:
            return False
        
        matched_line_upper = matched_line.upper().strip()
        http_method_upper = http_method.upper()
        
        # Check if matched_line starts with the HTTP method
        if not matched_line_upper.startswith(http_method_upper + ' '):
            return False
        
        # Extract path from matched_line (format: "METHOD /path HTTP/1.1" or "METHOD /path?query")
        # Try to extract path by splitting on space
        parts = matched_line.split(' ', 2)
        if len(parts) < 2:
            return False
        
        matched_path = parts[1]
        # Remove query string and fragment for comparison
        matched_path_base = matched_path.split('?')[0].split('#')[0]
        http_path_base = http_path.split('?')[0].split('#')[0]
        
        # Compare paths (case-insensitive)
        return matched_path_base.lower() == http_path_base.lower()
    
    def extract_and_display_match(match, field_name, payload_normalized, lines, host, is_http_response, http_method=None, http_path=None, flow_key=None):
        """Helper function to extract and display a matched credential"""
        value = None
        match_text = None
        
        # Extract value based on match groups
        if match.lastindex >= 1:
            # Try to get the value from the last group (usually the credential value)
            for i in range(match.lastindex, 0, -1):
                if match.group(i) and len(match.group(i)) > 3:
                    value = match.group(i)
                    match_text = match.group(0)
                    break
        
        # If no value found, use the full match
        if not value:
            value = match.group(0)
            match_text = match.group(0)
        
        # Validate value
        if len(value) < 3 or not value.isprintable() or value.isspace():
            return
        
        # Extract the line containing the match
        match_start = match.start()
        line_num = payload_normalized[:match_start].count('\n')
        
        if line_num < len(lines):
            matched_line = lines[line_num].strip()
            
            # Verify match is in the line
            if match_text not in matched_line and match.group(0) not in matched_line:
                return
            
            # Clean up the line
            matched_line = matched_line.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            matched_line = re.sub(r' +', ' ', matched_line).strip()
        else:
            matched_line = match_text
        
        # Format message with HTTP method and path
        msg_type = 'Response' if is_http_response else 'Request'
        method_path_info = ''
        # Only show method_path_info if matched_line doesn't already contain it
        if http_method and http_path and not should_hide_method_path(matched_line, http_method, http_path):
            method_path_info = f'{http_method} {http_path}\n'
        
        if host:
            msg = f'{method_path_info}Host: {host}\nPotential password submission:\n{msg_type}: {matched_line}'
        else:
            msg = f'{method_path_info}Potential password submission:\n{msg_type}: {matched_line}'
        
        # Log and display
        print_and_log(src, sport, dst, dport, msg, credential_key=f'HTTP-Field:{field_name}={value}')
        write_data('HTTP-PasswordFields.txt', matched_line, value)
        # Write full HTTP packet to HTTP-Raw.txt with paired request/response
        write_http_raw_with_pair('HTTP-Raw.txt', payload_normalized, f'{field_name}={value}', flow_key, is_http_response)
    
    # Use normalized payload for regex matching to ensure consistency
    # This will match password fields in URL query strings, POST body, and HTTP headers (Cookie, Authorization, etc.)
    for match in REGEX_PASSWORD_FIELDS.finditer(payload_normalized):
        value = match.group(2)
        if len(value) > 3 and value.isprintable() and not value.isspace():
            # Extract ONLY the line containing the match - never show other lines
            match_start = match.start()
            match_text = match.group(0)  # The full matched text (e.g., "&token=value")
            
            # Find which line contains the match by counting newlines before match position
            line_num = payload_normalized[:match_start].count('\n')
            
            # Get ONLY the line containing the match - ensure it's a single line
            if line_num < len(lines):
                matched_line = lines[line_num].strip()
                
                # Verify that the match is actually in this line
                # If match_text is not found in the line, something is wrong - skip it
                if match_text not in matched_line and match.group(0) not in matched_line:
                    # Match not found in the line - this shouldn't happen, skip this match
                    continue
                
                # Remove any remaining newlines/carriage returns to ensure single line
                matched_line = matched_line.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                # Collapse multiple spaces to single space
                import re as re_module
                matched_line = re_module.sub(r' +', ' ', matched_line).strip()

            else:
                # Match not in any line (shouldn't happen), just show match itself
                matched_line = match_text
            
            # Determine if this is a request or response for message formatting
            msg_type = 'Response' if is_http_response else 'Request'
            
            # Format message with HTTP method and path
            method_path_info = ''
            # Only show method_path_info if matched_line doesn't already contain it
            if http_method and http_path and matched_line:
                if not should_hide_method_path(matched_line, http_method, http_path):
                    method_path_info = f'{http_method} {http_path}\n'
            elif http_method and http_path:
                # If matched_line is empty, always show method_path_info
                method_path_info = f'{http_method} {http_path}\n'
            
            if matched_line:
                if host:
                    msg = f'{method_path_info}Host: {host}\nPotential password submission:\n{msg_type}: {matched_line}'
                else:
                    msg = f'{method_path_info}Potential password submission:\n{msg_type}: {matched_line}'
                display_line = matched_line
            else:
                # Fallback: show just the match itself
                match_text = match.group(0)
                if host:
                    msg = f'{method_path_info}Host: {host}\nPotential password submission:\n{msg_type}: {match_text}'
                else:
                    msg = f'{method_path_info}Potential password submission:\n{msg_type}: {match_text}'
                display_line = match_text
            
            # Use field name and value as credential key for deduplication
            field_name = match.group(1)
            
            print_and_log(src, sport, dst, dport, msg, credential_key=f'HTTP-Field:{field_name}={value}')
            write_data('HTTP-PasswordFields.txt', display_line, value)
            # Write full HTTP packet to HTTP-Raw.txt with paired request/response
            write_http_raw_with_pair('HTTP-Raw.txt', payload_normalized, f'{field_name}={value}', flow_key, is_http_response)
    
    # Cookie extraction (if enabled)
    if enable_cookie:
        for match in REGEX_COOKIE.finditer(payload_normalized):
            cookie_name = match.group(1).strip()
            cookie_value = match.group(2).strip()
            if len(cookie_value) > 3 and cookie_value.isprintable() and not cookie_value.isspace():
                # Extract the line containing the match
                match_start = match.start()
                line_num = payload_normalized[:match_start].count('\n')
                
                if line_num < len(lines):
                    matched_line = lines[line_num].strip()
                    matched_line = matched_line.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                    matched_line = re.sub(r' +', ' ', matched_line).strip()
                else:
                    matched_line = match.group(0)
                
                # Format message
                msg_type = 'Response' if is_http_response else 'Request'
                method_path_info = ''
                if http_method and http_path and not should_hide_method_path(matched_line, http_method, http_path):
                    method_path_info = f'{http_method} {http_path}\n'
                
                if host:
                    msg = f'{method_path_info}Host: {host}\nPotential password submission:\n{msg_type}: {matched_line}'
                else:
                    msg = f'{method_path_info}Potential password submission:\n{msg_type}: {matched_line}'
                
                print_and_log(src, sport, dst, dport, msg, credential_key=f'HTTP-Cookie:{cookie_name}={cookie_value}')
                write_data('HTTP-PasswordFields.txt', matched_line, cookie_value)
                write_http_raw_with_pair('HTTP-Raw.txt', payload_normalized, f'Cookie:{cookie_name}={cookie_value}', flow_key, is_http_response)
    
    # Additional regex patterns for enhanced credential detection
    # Access key patterns (access_key_id, access-key-secret, LTAI*)
    for match in REGEX_ACCESS_KEY.finditer(payload_normalized):
        extract_and_display_match(match, 'access_key', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # Corp ID/Secret patterns
    for match in REGEX_CORP_CRED.finditer(payload_normalized):
        extract_and_display_match(match, 'corp_cred', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # JDBC connection strings
    for match in REGEX_JDBC.finditer(payload_normalized):
        extract_and_display_match(match, 'jdbc', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # Basic/Bearer token patterns (excluding Authorization header which is already handled)
    for match in REGEX_AUTH_TOKEN.finditer(payload_normalized):
        # Skip if it's in Authorization header (already handled by REGEX_HTTP_BASIC)
        match_start = match.start()
        line_num = payload_normalized[:match_start].count('\n')
        if line_num < len(lines):
            line_lower = lines[line_num].lower()
            if 'authorization:' in line_lower:
                continue
        extract_and_display_match(match, 'auth_token', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # JavaScript password patterns
    for match in REGEX_JS_PASSWORD.finditer(payload_normalized):
        extract_and_display_match(match, 'js_password', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # JavaScript key/secret/token patterns
    for match in REGEX_JS_KEY_SECRET.finditer(payload_normalized):
        extract_and_display_match(match, 'js_key_secret', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)
    
    # XML Key tags
    for match in REGEX_XML_KEY.finditer(payload_normalized):
        extract_and_display_match(match, 'xml_key', payload_normalized, lines, host, is_http_response, http_method, http_path, flow_key)

def extract_smtp_auth(payload, src, sport, dst, dport):
    """Extract SMTP authentication"""
    if is_protocol_disabled('SMTP'):
        return
        
    if dport not in {25, 587, 465} and sport not in {25, 587, 465}:
        return
        
    lines = payload.split(b'\r\n')
    flow_key = get_flow_key(src, sport, dst, dport)
    
    for line in lines:
        line = line.strip()
        if line.upper().startswith(b'AUTH PLAIN '):
            try:
                creds_bytes = base64.b64decode(line[11:])
                creds = creds_bytes.decode('utf-8', errors='ignore')
                parts = creds.split('\x00')
                if len(parts) >= 3 and parts[1] and parts[2]:
                    user, pwd = parts[1], parts[2]
                    msg = f'SMTP AUTH PLAIN: {user}:{pwd}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'SMTP:{user}:{pwd}')
                    write_data('SMTP-Plaintext.txt', f'{user}:{pwd}', f'{user}:{pwd}')
            except (base64.binascii.Error, UnicodeDecodeError, IndexError):
                pass
                
        elif line.upper().startswith(b'AUTH LOGIN'):
            pass
            
        elif flow_key in ftp_users and line:
            try:
                pwd = base64.b64decode(line).decode('utf-8', errors='ignore')
                if pwd:
                    smtp_user = ftp_users[flow_key]
                    msg = f'SMTP AUTH LOGIN: {smtp_user}:{pwd}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'SMTP:{smtp_user}:{pwd}')
                    write_data('SMTP-Plaintext.txt', f'{smtp_user}:{pwd}', f'{smtp_user}:{pwd}')
                del ftp_users[flow_key]
            except (base64.binascii.Error, UnicodeDecodeError):
                pass
                
        elif line:
            try:
                user = base64.b64decode(line).decode('utf-8', errors='ignore')
                if user and '@' in user:
                    ftp_users[flow_key] = user
            except (base64.binascii.Error, UnicodeDecodeError):
                pass

def extract_ldap_simple_bind(payload, src, sport, dst, dport):
    """Extract LDAP Simple Bind credentials"""
    if is_protocol_disabled('LDAP'):
        return
        
    if dport not in {389, 636} and sport not in {389, 636}:
        return
        
    if len(payload) < 10 or payload[0] != 0x30:
        return
        
    try:
        pos = 1
        length = payload[pos]
        pos += 1
        
        if length & 0x80:
            len_bytes = length & 0x7F
            if pos + len_bytes > len(payload):
                return
            length = int.from_bytes(payload[pos:pos + len_bytes], 'big')
            pos += len_bytes
        
        if pos + 3 > len(payload) or payload[pos] != 0x02:
            return
        pos += 2 + payload[pos + 1]
        
        if pos + 1 > len(payload) or payload[pos] != 0x60:
            return
        pos += 1
        
        bind_length = payload[pos]
        pos += 1
        if bind_length & 0x80:
            len_bytes = bind_length & 0x7F
            if pos + len_bytes > len(payload):
                return
            pos += len_bytes
        
        if pos + 3 > len(payload) or payload[pos] != 0x02:
            return
        pos += 2 + payload[pos + 1]
        
        if pos + 2 > len(payload) or payload[pos] != 0x04:
            return
        dn_len = payload[pos + 1]
        pos += 2
        
        if pos + dn_len > len(payload):
            return
        dn = payload[pos:pos + dn_len].decode('utf-8', errors='ignore')
        pos += dn_len
        
        if pos + 2 > len(payload):
            return
        
        if payload[pos:pos + 2] == b'\x80\x00':
            msg = f'LDAP Simple Bind: {dn} : (empty password)'
            print_and_log(src, sport, dst, dport, msg, credential_key=f'LDAP:{dn}:(empty)')
            write_data('LDAP-Simple.txt', f'{dn}:(empty)', f'{dn}:(empty)')
        elif payload[pos] == 0x80:
            pwd_len = payload[pos + 1]
            pos += 2
            if pos + pwd_len > len(payload):
                return
            pwd = payload[pos:pos + pwd_len].decode('utf-8', errors='ignore')
            msg = f'LDAP Simple Bind: {dn} : {pwd}'
            print_and_log(src, sport, dst, dport, msg, credential_key=f'LDAP:{dn}:{pwd}')
            write_data('LDAP-Simple.txt', f'{dn}:{pwd}', f'{dn}:{pwd}')
    except (IndexError, UnicodeDecodeError, struct.error):
        pass

def extract_kerberos(payload, src, sport, dst, dport):
    """Extract Kerberos AS-REQ Pre-Auth (etype 23)"""
    if is_protocol_disabled('KERBEROS'):
        return
        
    if len(payload) < 50:
        return
        
    try:
        MsgType = payload[17:18]
        EncType = payload[39:40]
        
        if MsgType == b"\x0a" and EncType == b"\x17":
            if payload[40:44] in {b"\xa2\x36\x04\x34", b"\xa2\x35\x04\x33"}:
                HashLen = struct.unpack('<b', payload[41:42])[0]
                if HashLen in {53, 54}:
                    Hash = payload[44:44 + HashLen]
                    SwitchHash = Hash[16:] + Hash[0:16]
                    
                    name_offset = 144 if HashLen == 54 else 143
                    NameLen = struct.unpack('<b', payload[name_offset:name_offset + 1])[0]
                    Name = payload[name_offset + 1:name_offset + 1 + NameLen]
                    
                    domain_offset = name_offset + 1 + NameLen + 3
                    DomainLen = struct.unpack('<b', payload[domain_offset:domain_offset + 1])[0]
                    Domain = payload[domain_offset + 1:domain_offset + 1 + DomainLen]
                    
                    BuildHash = f'$krb5pa$23${Name.decode("latin-1")}${Domain.decode("latin-1").upper()}$dummy${binascii.hexlify(SwitchHash).decode("latin-1").upper()}'
                    msg = f'MSKerb hash found: {BuildHash}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'Kerberos:{Name.decode("latin-1")}')
                    write_data('MSKerb.txt', BuildHash, Name.decode('latin-1'))
            else:
                HashLen = struct.unpack('<b', payload[48:49])[0]
                Hash = payload[49:49 + HashLen]
                SwitchHash = Hash[16:] + Hash[0:16]
                
                NameLen = struct.unpack('<b', payload[HashLen + 97:HashLen + 98])[0]
                Name = payload[HashLen + 98:HashLen + 98 + NameLen]
                
                DomainLen = struct.unpack('<b', payload[HashLen + 98 + NameLen + 3:HashLen + 98 + NameLen + 4])[0]
                Domain = payload[HashLen + 98 + NameLen + 4:HashLen + 98 + NameLen + 4 + DomainLen]
                
                BuildHash = f'$krb5pa$23${Name.decode("latin-1")}${Domain.decode("latin-1").upper()}$dummy${binascii.hexlify(SwitchHash).decode("latin-1").upper()}'
                msg = f'MSKerb hash found: {BuildHash}'
                print_and_log(src, sport, dst, dport, msg, credential_key=f'Kerberos:{Name.decode("latin-1")}')
                write_data('MSKerb.txt', BuildHash, Name.decode('latin-1'))
    except (IndexError, struct.error, UnicodeDecodeError):
        pass

def extract_cleartext(payload, src, sport, dst, dport):
    """Extract cleartext credentials (IRC, FTP, SNMP, MSSQL)"""
    flow_key = get_flow_key(src, sport, dst, dport)
    lines = payload.split(b'\r\n')
    
    # Detect IRC vs FTP
    is_irc = (dport in range(6660, 6670) or sport in range(6660, 6670) or 
              dport in {6697, 7000} or sport in {6697, 7000})
    
    if not is_irc:
        for line in lines:
            if line.upper().startswith(b'NICK ') or line.upper().startswith(b'JOIN '):
                is_irc = True
                break
    
    for line in lines:
        line = line.strip()
        
        if is_irc and not is_protocol_disabled('IRC'):
            # IRC protocol
            if line.upper().startswith(b'NICK '):
                nick = line[5:].decode('utf-8', errors='ignore').strip()
                msg = f'IRC Nick: {nick}'
                print_and_log(src, sport, dst, dport, msg, credential_key=f'IRC:nick:{nick}')
            elif line.upper().startswith(b'USER '):
                parts = line[5:].decode('utf-8', errors='ignore').strip().split()
                if parts:
                    user = parts[0]
                    ftp_users[flow_key] = user
                    msg = f'IRC User: {user}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'IRC:user:{user}')
            elif line.upper().startswith(b'PASS '):
                pwd = line[5:].decode('utf-8', errors='ignore').strip()
                msg = f'IRC Pass: {pwd}'
                if flow_key in ftp_users:
                    creds = f'{ftp_users[flow_key]}:{pwd}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'IRC:{creds}')
                    write_data('IRC-Plaintext.txt', creds, creds)
                    del ftp_users[flow_key]
                else:
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'IRC:pass:{pwd}')
        elif not is_protocol_disabled('FTP'):
            # FTP protocol
            if line.upper().startswith(b'USER '):
                user = line[5:].decode('utf-8', errors='ignore').strip()
                ftp_users[flow_key] = user
                msg = f'FTP User: {user}'
                print_and_log(src, sport, dst, dport, msg, credential_key=f'FTP:user:{user}')
                
            elif line.upper().startswith(b'PASS '):
                pwd = line[5:].decode('utf-8', errors='ignore').strip()
                msg = f'FTP Pass: {pwd}'
                if flow_key in ftp_users:
                    creds = f'{ftp_users[flow_key]}:{pwd}'
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'FTP:{creds}')
                    write_data('FTP-Plaintext.txt', creds, creds)
                    del ftp_users[flow_key]
                else:
                    print_and_log(src, sport, dst, dport, msg, credential_key=f'FTP:pass:{pwd}')
    
    # SNMP
    if not is_protocol_disabled('SNMP') and (dport in {161, 162} or sport in {161, 162}):
        if len(payload) > 20 and payload[0:1] == b'\x30':
            try:
                snmpv1 = payload[4:6] == b'\x02\x01' and payload[6] in {0, 1}
                snmpv2c = payload[2:4] == b'\x02\x01' and payload[4] in {0, 1}
                if (snmpv1) or (snmpv2c):
                    comm_idx = payload.find(b'\x04', 7) if snmpv1 else payload.find(b'\x04', 5)
                    if comm_idx != -1:
                        comm_len = payload[comm_idx + 1]
                        if 0 < comm_len < 50:
                            comm = payload[comm_idx + 2:comm_idx + 2 + comm_len].decode('utf-8', errors='ignore')
                            if comm.isprintable() and not comm.isspace():
                                version = "SNMPv1" if snmpv1 else "SNMPv2c"
                                msg = f'Found {version} Community string: {comm}'
                                write_data(f'{version}.txt', comm, comm)
                                print_and_log(src, sport, dst, dport, msg, credential_key=f'SNMP:{comm}')
            except (IndexError, UnicodeDecodeError):
                pass
    
    # MSSQL
    if not is_protocol_disabled('MSSQL') and (dport == 1433 or sport == 1433):
        mssql_msg = parse_mssql_plaintext(payload)
        if mssql_msg:
            print_and_log(src, sport, dst, dport, mssql_msg)
            try:
                username = mssql_msg.split('Password: ')[0].split('Username: ')[1]
                write_data('MSSQL-Plaintext.txt', mssql_msg, username)
            except IndexError:
                pass

def parse_mssql_plaintext(payload):
    """Parse MSSQL TDS login packet"""
    try:
        if len(payload) < 58 or payload[0:2] != b'\x10\x01':
            return None
            
        username_offset = struct.unpack('<H', payload[48:50])[0]
        pwd_offset = struct.unpack('<H', payload[52:54])[0]
        app_offset = struct.unpack('<H', payload[56:58])[0]
        
        pwd_len = app_offset - pwd_offset
        username_len = pwd_offset - username_offset
        
        if pwd_len <= 0 or username_len <= 0 or pwd_len > 200 or username_len > 200:
            return None
        
        pwd_str = payload[8 + pwd_offset:8 + pwd_offset + pwd_len]
        pwd = bytes(b ^ 0xa5 for b in pwd_str)
        pwd = pwd[::-1].decode('utf-16le', errors='ignore').strip('\x00')
        
        username = payload[8 + username_offset:8 + username_offset + username_len].decode('utf-16le', errors='ignore').strip('\x00')
        
        if not username or not pwd:
            return None
            
        return f"MSSQL Username: {username} Password: {pwd}"
    except (IndexError, struct.error, UnicodeDecodeError):
        return None

def process_packet(packet):
    """Process a single packet"""
    global detected_offset
    
    if len(packet) < 40:
        return
    
    # Auto-detect link layer offset (cached after first packet)
    if detected_offset is not None:
        offset = detected_offset
        if len(packet) >= offset + 20:
            search_payload = packet[offset:]
        else:
            return
    else:
        # First packet: detect offset
        for offset in [16, 14, 0]:
            if len(packet) < offset + 20:
                continue
            search_payload = packet[offset:]
            if len(search_payload) >= 20 and (search_payload[0] & 0xF0) == 0x40:
                detected_offset = offset
                break
        else:
            if len(packet) < 54:
                return
            search_payload = packet[14:]
            detected_offset = 14
        
    if len(search_payload) < 20:
        return
        
    try:
        ip_hlen = (search_payload[0] & 0x0f) * 4
        if len(search_payload) < ip_hlen + 10:
            return
            
        proto = search_payload[9]
        src = '.'.join(str(b) for b in search_payload[12:16])
        dst = '.'.join(str(b) for b in search_payload[16:20])
        
        # Skip packets from/to excluded hosts
        if src in excluded_hosts or dst in excluded_hosts:
            return
        
        if proto == 6:  # TCP
            tcp_offset = ip_hlen
            if len(search_payload) < tcp_offset + 20:
                return
            tcp_hlen = (search_payload[tcp_offset + 12] >> 4) * 4
            payload = search_payload[tcp_offset + tcp_hlen:]
            sport, dport = struct.unpack('>HH', search_payload[tcp_offset:tcp_offset + 4])
            
        elif proto == 17:  # UDP
            payload = search_payload[ip_hlen + 8:]
            sport, dport = struct.unpack('>HH', search_payload[ip_hlen:ip_hlen + 4])
            
        else:
            payload = b''
            sport = dport = 0
        
        # Extract credentials from various protocols
        extract_ntlm(search_payload, src, sport, dst, dport)
        extract_ntlm_from_http(payload, src, sport, dst, dport)
        extract_http_basic(payload, src, sport, dst, dport)
        extract_http_password_fields(payload, src, sport, dst, dport, args.enable_https, args.enable_http_response, args.enable_cookie)
        extract_smtp_auth(payload, src, sport, dst, dport)
        extract_ldap_simple_bind(payload, src, sport, dst, dport)
        
        if dport == 88 or sport == 88:
            extract_kerberos(payload, src, sport, dst, dport)
            
        extract_cleartext(payload, src, sport, dst, dport)
        
    except (IndexError, struct.error):
        pass

def process_pcap(fname):
    """Process a PCAP/PCAPNG file"""
    global detected_offset, ntlm_challenge, ftp_users, seen_credentials, logged_messages, http_flows
    
    # Reset state for new file
    detected_offset = None
    ntlm_challenge.clear()
    ftp_users.clear()
    seen_credentials.clear()
    logged_messages.clear()
    http_flows.clear()
    
    start_time = time.time()
    file_size = os.path.getsize(fname) / (1024 * 1024)
    print(f'Parsing {fname}...')
    
    reader = pcapy.open_offline(fname)
    packet_count = 0
    
    while True:
        header, packet = reader.next()
        if not header:
            break
        process_packet(packet)
        packet_count += 1
    
    elapsed = time.time() - start_time
    if elapsed >= 60:
        print(f'\n{fname} parsed in: {elapsed/60:.3g} minutes ({packet_count:,} packets, {file_size:.3g} MB).\n')
    else:
        print(f'\n{fname} parsed in: {elapsed:.4g} seconds ({packet_count:,} packets, {file_size:.3g} MB).\n')

def run():
    """Main execution"""
    # print(f'{VERSION}\nAuthor: Laurent Gaffie\nContact: lgaffie@secorizon.com\nX: @secorizon\n')
    print(f'{VERSION}\n')
    
    if args.activate_cc:
        print("CC number scanning activated\n")
    else:
        print("CC number scanning deactivated\n")
    
    if args.interface:
        print(f'Live capture on {args.interface}\n')
        reader = pcapy.open_live(args.interface, 65536, True, 100)
        reader.loop(-1, lambda hdr, data: process_packet(data))
        
    elif args.fname:
        process_pcap(args.fname)
        
    elif args.dir_path:
        for root, _, files in os.walk(args.dir_path):
            for file in files:
                if file.lower().endswith(('.pcap', '.pcapng')):
                    path = os.path.join(root, file)
                    process_pcap(path)

def signal_handler(sig, frame):
    """Handle Ctrl+C gracefully"""
    print('\n\nExiting...')
    sys.exit(0)

if __name__ == '__main__':
    # Register signal handler for graceful exit on Ctrl+C
    signal.signal(signal.SIGINT, signal_handler)
    
    parser = argparse.ArgumentParser(description=VERSION)
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('-f', dest='fname', help='Pcap file to parse')
    group.add_argument('-d', dest='dir_path', help='Pcap directory to parse recursively')
    group.add_argument('-i', dest='interface', help='Interface for live capture')
    parser.add_argument('-c', action='store_false', dest='activate_cc', default=True, help='Deactivate CC number scanning')
    parser.add_argument('-t', action='store_true', dest='timestamp', help='Print timestamps')
    parser.add_argument('-v', action='store_true', dest='verbose', help='Verbose mode (print duplicates)')
    parser.add_argument('-o', dest='output_path', default='./', help='Output directory for logs')
    parser.add_argument('--disable', dest='disable_protocols', action='append', 
                        help='Disable protocol (can be used multiple times). Options: NTLM, HTTP, FTP, IRC, LDAP, SMTP, Kerberos, SNMP, MSSQL')
    parser.add_argument('--exclude-host', dest='exclude_hosts', action='append',
                        help='Exclude host IP from capture (can be used multiple times)')
    parser.add_argument('--enable-https', action='store_true', dest='enable_https', default=False, help='Enable HTTPS decryption')
    parser.add_argument('--enable-http-response', action='store_true', dest='enable_http_response', default=False, help='Enable HTTP response scan')
    parser.add_argument('--enable-cookie', action='store_true', dest='enable_cookie', default=False, help='Enable Cookie extraction')
    args = parser.parse_args()
    
    # Process disabled protocols
    if args.disable_protocols:
        disabled_protocols.update(p.upper() for p in args.disable_protocols)
        protocols_str = ', '.join(sorted(disabled_protocols))
        print(f"Disabled protocols: {protocols_str}\n")
    
    # Process excluded hosts
    if args.exclude_hosts:
        excluded_hosts.update(args.exclude_hosts)
        hosts_str = ', '.join(sorted(excluded_hosts))
        print(f"Excluded hosts: {hosts_str}\n")

    output_path = args.output_path.rstrip('/')
    os.makedirs(os.path.join(output_path, 'logs'), exist_ok=True)
    session_log = os.path.join(output_path, 'CredentialDump-Session.log')

    logger = logging.getLogger('PCredz')
    logger.setLevel(logging.WARNING)
    logger.addHandler(logging.FileHandler(session_log, encoding='utf-8'))

    try:
        run()
    except KeyboardInterrupt:
        print('\n\nExiting...')
        sys.exit(0)
